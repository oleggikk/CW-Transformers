{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfa43bd5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7066188e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb102843",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from random import shuffle\n",
    "from PIL import Image\n",
    "from ipywidgets import IntProgress, HTML, VBox\n",
    "from IPython.display import display\n",
    "\n",
    "import glob\n",
    "from itertools import chain\n",
    "import os\n",
    "import random\n",
    "import zipfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import ViTForImageClassification, AdamW\n",
    "import copy\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77a8ba70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Oleg\\Desktop\\Caltech256\\train      C:\\Users\\Oleg\\Desktop\\Caltech256\\test      C:\\Users\\Oleg\\Desktop\\Caltech256\\valid\n"
     ]
    }
   ],
   "source": [
    "TARGET_SIZE = (224, 224) \n",
    "INPUT_SIZE = (224, 224) \n",
    "\n",
    "DATA_DIR = r\"C:\\Users\\Oleg\\Desktop\\Caltech256\"\n",
    "\n",
    "train_dir = r\"C:\\Users\\Oleg\\Desktop\\Caltech256\\train\"\n",
    "test_dir = r\"C:\\Users\\Oleg\\Desktop\\Caltech256\\test\"\n",
    "val_dir = r\"C:\\Users\\Oleg\\Desktop\\Caltech256\\valid\"\n",
    "print(train_dir, \"    \", test_dir, \"    \", val_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eddc1cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Training settings\n",
    "batch_size = 16\n",
    "epochs = 10\n",
    "lr = 3e-5\n",
    "gamma = 0.7\n",
    "seed = 42\n",
    "device = 'cuda'\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ec88a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {'num_workers': 4, 'pin_memory': True} if use_cuda else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2af1aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE=224 \n",
    "train_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((IMG_SIZE,IMG_SIZE)),\n",
    "        transforms.RandomResizedCrop(IMG_SIZE),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((IMG_SIZE,IMG_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdd2e00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.ImageFolder(root=train_dir, transform=train_transforms)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, **kwargs)\n",
    "test_dataset = datasets.ImageFolder(root=test_dir, transform=test_transforms)\n",
    "test_loader  = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, **kwargs) \n",
    "val_dataset = datasets.ImageFolder(root=val_dir, transform=test_transforms)\n",
    "val_loader  = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False, **kwargs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4f2f9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21315 6272 3020\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset), len(test_dataset), len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a96cd7d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257\n"
     ]
    }
   ],
   "source": [
    "num_classes=len(train_dataset.classes)\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d80e150a",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7bc563b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, loader):\n",
    "    epoch_val_accuracy = 0\n",
    "    epoch_val_loss = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data, label in loader:\n",
    "            data = data.to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            val_output = model(data)\n",
    "            val_loss = criterion(val_output, label)\n",
    "\n",
    "            acc = (val_output.argmax(dim=1) == label).float().sum()\n",
    "            epoch_val_accuracy += acc\n",
    "            epoch_val_loss += val_loss\n",
    "    epoch_val_accuracy /= len(test_dataset)\n",
    "    epoch_val_loss /= len(test_dataset)\n",
    "    return epoch_val_accuracy,epoch_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bfbd3f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,n_epochs=epochs, learningrate=lr, val_loader=val_loader):\n",
    "    optimizer=optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=learningrate)\n",
    "    # scheduler\n",
    "    #scheduler = StepLR(optimizer, step_size=1, gamma=gamma)\n",
    "    best_acc=0\n",
    "    best_model=None\n",
    "    for epoch in range(n_epochs):\n",
    "        epoch_loss = 0\n",
    "        epoch_accuracy = 0\n",
    "        model.train()\n",
    "        for data, label in tqdm(train_loader):\n",
    "            data = data.to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            output = model(data)\n",
    "            loss = criterion(output, label)\n",
    "\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            acc = (output.argmax(dim=1) == label).float().sum()\n",
    "            epoch_accuracy += acc\n",
    "            epoch_loss += loss\n",
    "        epoch_accuracy /= len(train_dataset)\n",
    "        epoch_loss /= len(train_dataset)\n",
    "\n",
    "        epoch_val_accuracy,epoch_val_loss=test(model, val_loader)\n",
    "        print(\n",
    "            f\"Epoch : {epoch+1} - loss : {epoch_loss:.4f} - acc: {epoch_accuracy:.4f} - val_loss : {epoch_val_loss:.4f} - val_acc: {epoch_val_accuracy:.4f}\\n\"\n",
    "        )\n",
    "        if best_acc<epoch_val_accuracy:\n",
    "            best_acc=epoch_val_accuracy\n",
    "            best_model=copy.deepcopy(model.state_dict())\n",
    "        #scheduler.step()\n",
    "    \n",
    "    if best_model is not None:\n",
    "        model.load_state_dict(best_model)\n",
    "        print(f\"Best acc:{best_acc}\")\n",
    "        epoch_val_accuracy,epoch_val_loss=test(model, val_loader)\n",
    "        print(\n",
    "            f\"val_loss : {epoch_val_loss:.4f} - val_acc: {epoch_val_accuracy:.4f}\\n\"\n",
    "        )\n",
    "    else:\n",
    "        print(f\"No best model Best acc:{best_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f7ce6e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adv_inception_v3',\n",
       " 'bat_resnext26ts',\n",
       " 'beit_base_patch16_224',\n",
       " 'beit_base_patch16_224_in22k',\n",
       " 'beit_base_patch16_384',\n",
       " 'beit_large_patch16_224',\n",
       " 'beit_large_patch16_224_in22k',\n",
       " 'beit_large_patch16_384',\n",
       " 'beit_large_patch16_512',\n",
       " 'beitv2_base_patch16_224',\n",
       " 'beitv2_base_patch16_224_in22k',\n",
       " 'beitv2_large_patch16_224',\n",
       " 'beitv2_large_patch16_224_in22k',\n",
       " 'botnet26t_256',\n",
       " 'botnet50ts_256',\n",
       " 'cait_m36_384',\n",
       " 'cait_m48_448',\n",
       " 'cait_s24_224',\n",
       " 'cait_s24_384',\n",
       " 'cait_s36_384',\n",
       " 'cait_xs24_384',\n",
       " 'cait_xxs24_224',\n",
       " 'cait_xxs24_384',\n",
       " 'cait_xxs36_224',\n",
       " 'cait_xxs36_384',\n",
       " 'coat_lite_mini',\n",
       " 'coat_lite_small',\n",
       " 'coat_lite_tiny',\n",
       " 'coat_mini',\n",
       " 'coat_tiny',\n",
       " 'coatnet_0_224',\n",
       " 'coatnet_0_rw_224',\n",
       " 'coatnet_1_224',\n",
       " 'coatnet_1_rw_224',\n",
       " 'coatnet_2_224',\n",
       " 'coatnet_2_rw_224',\n",
       " 'coatnet_3_224',\n",
       " 'coatnet_3_rw_224',\n",
       " 'coatnet_4_224',\n",
       " 'coatnet_5_224',\n",
       " 'coatnet_bn_0_rw_224',\n",
       " 'coatnet_nano_cc_224',\n",
       " 'coatnet_nano_rw_224',\n",
       " 'coatnet_pico_rw_224',\n",
       " 'coatnet_rmlp_0_rw_224',\n",
       " 'coatnet_rmlp_1_rw_224',\n",
       " 'coatnet_rmlp_2_rw_224',\n",
       " 'coatnet_rmlp_3_rw_224',\n",
       " 'coatnet_rmlp_nano_rw_224',\n",
       " 'coatnext_nano_rw_224',\n",
       " 'convit_base',\n",
       " 'convit_small',\n",
       " 'convit_tiny',\n",
       " 'convmixer_768_32',\n",
       " 'convmixer_1024_20_ks9_p14',\n",
       " 'convmixer_1536_20',\n",
       " 'convnext_atto',\n",
       " 'convnext_atto_ols',\n",
       " 'convnext_base',\n",
       " 'convnext_base_384_in22ft1k',\n",
       " 'convnext_base_in22ft1k',\n",
       " 'convnext_base_in22k',\n",
       " 'convnext_femto',\n",
       " 'convnext_femto_ols',\n",
       " 'convnext_large',\n",
       " 'convnext_large_384_in22ft1k',\n",
       " 'convnext_large_in22ft1k',\n",
       " 'convnext_large_in22k',\n",
       " 'convnext_nano',\n",
       " 'convnext_nano_ols',\n",
       " 'convnext_pico',\n",
       " 'convnext_pico_ols',\n",
       " 'convnext_small',\n",
       " 'convnext_small_384_in22ft1k',\n",
       " 'convnext_small_in22ft1k',\n",
       " 'convnext_small_in22k',\n",
       " 'convnext_tiny',\n",
       " 'convnext_tiny_384_in22ft1k',\n",
       " 'convnext_tiny_hnf',\n",
       " 'convnext_tiny_in22ft1k',\n",
       " 'convnext_tiny_in22k',\n",
       " 'convnext_xlarge_384_in22ft1k',\n",
       " 'convnext_xlarge_in22ft1k',\n",
       " 'convnext_xlarge_in22k',\n",
       " 'crossvit_9_240',\n",
       " 'crossvit_9_dagger_240',\n",
       " 'crossvit_15_240',\n",
       " 'crossvit_15_dagger_240',\n",
       " 'crossvit_15_dagger_408',\n",
       " 'crossvit_18_240',\n",
       " 'crossvit_18_dagger_240',\n",
       " 'crossvit_18_dagger_408',\n",
       " 'crossvit_base_240',\n",
       " 'crossvit_small_240',\n",
       " 'crossvit_tiny_240',\n",
       " 'cs3darknet_focus_l',\n",
       " 'cs3darknet_focus_m',\n",
       " 'cs3darknet_focus_s',\n",
       " 'cs3darknet_focus_x',\n",
       " 'cs3darknet_l',\n",
       " 'cs3darknet_m',\n",
       " 'cs3darknet_s',\n",
       " 'cs3darknet_x',\n",
       " 'cs3edgenet_x',\n",
       " 'cs3se_edgenet_x',\n",
       " 'cs3sedarknet_l',\n",
       " 'cs3sedarknet_x',\n",
       " 'cs3sedarknet_xdw',\n",
       " 'cspdarknet53',\n",
       " 'cspresnet50',\n",
       " 'cspresnet50d',\n",
       " 'cspresnet50w',\n",
       " 'cspresnext50',\n",
       " 'darknet17',\n",
       " 'darknet21',\n",
       " 'darknet53',\n",
       " 'darknetaa53',\n",
       " 'deit3_base_patch16_224',\n",
       " 'deit3_base_patch16_224_in21ft1k',\n",
       " 'deit3_base_patch16_384',\n",
       " 'deit3_base_patch16_384_in21ft1k',\n",
       " 'deit3_huge_patch14_224',\n",
       " 'deit3_huge_patch14_224_in21ft1k',\n",
       " 'deit3_large_patch16_224',\n",
       " 'deit3_large_patch16_224_in21ft1k',\n",
       " 'deit3_large_patch16_384',\n",
       " 'deit3_large_patch16_384_in21ft1k',\n",
       " 'deit3_medium_patch16_224',\n",
       " 'deit3_medium_patch16_224_in21ft1k',\n",
       " 'deit3_small_patch16_224',\n",
       " 'deit3_small_patch16_224_in21ft1k',\n",
       " 'deit3_small_patch16_384',\n",
       " 'deit3_small_patch16_384_in21ft1k',\n",
       " 'deit_base_distilled_patch16_224',\n",
       " 'deit_base_distilled_patch16_384',\n",
       " 'deit_base_patch16_224',\n",
       " 'deit_base_patch16_384',\n",
       " 'deit_small_distilled_patch16_224',\n",
       " 'deit_small_patch16_224',\n",
       " 'deit_tiny_distilled_patch16_224',\n",
       " 'deit_tiny_patch16_224',\n",
       " 'densenet121',\n",
       " 'densenet121d',\n",
       " 'densenet161',\n",
       " 'densenet169',\n",
       " 'densenet201',\n",
       " 'densenet264',\n",
       " 'densenet264d_iabn',\n",
       " 'densenetblur121d',\n",
       " 'dla34',\n",
       " 'dla46_c',\n",
       " 'dla46x_c',\n",
       " 'dla60',\n",
       " 'dla60_res2net',\n",
       " 'dla60_res2next',\n",
       " 'dla60x',\n",
       " 'dla60x_c',\n",
       " 'dla102',\n",
       " 'dla102x',\n",
       " 'dla102x2',\n",
       " 'dla169',\n",
       " 'dm_nfnet_f0',\n",
       " 'dm_nfnet_f1',\n",
       " 'dm_nfnet_f2',\n",
       " 'dm_nfnet_f3',\n",
       " 'dm_nfnet_f4',\n",
       " 'dm_nfnet_f5',\n",
       " 'dm_nfnet_f6',\n",
       " 'dpn68',\n",
       " 'dpn68b',\n",
       " 'dpn92',\n",
       " 'dpn98',\n",
       " 'dpn107',\n",
       " 'dpn131',\n",
       " 'eca_botnext26ts_256',\n",
       " 'eca_halonext26ts',\n",
       " 'eca_nfnet_l0',\n",
       " 'eca_nfnet_l1',\n",
       " 'eca_nfnet_l2',\n",
       " 'eca_nfnet_l3',\n",
       " 'eca_resnet33ts',\n",
       " 'eca_resnext26ts',\n",
       " 'eca_vovnet39b',\n",
       " 'ecaresnet26t',\n",
       " 'ecaresnet50d',\n",
       " 'ecaresnet50d_pruned',\n",
       " 'ecaresnet50t',\n",
       " 'ecaresnet101d',\n",
       " 'ecaresnet101d_pruned',\n",
       " 'ecaresnet200d',\n",
       " 'ecaresnet269d',\n",
       " 'ecaresnetlight',\n",
       " 'ecaresnext26t_32x4d',\n",
       " 'ecaresnext50t_32x4d',\n",
       " 'edgenext_base',\n",
       " 'edgenext_small',\n",
       " 'edgenext_small_rw',\n",
       " 'edgenext_x_small',\n",
       " 'edgenext_xx_small',\n",
       " 'efficientformer_l1',\n",
       " 'efficientformer_l3',\n",
       " 'efficientformer_l7',\n",
       " 'efficientnet_b0',\n",
       " 'efficientnet_b0_g8_gn',\n",
       " 'efficientnet_b0_g16_evos',\n",
       " 'efficientnet_b0_gn',\n",
       " 'efficientnet_b1',\n",
       " 'efficientnet_b1_pruned',\n",
       " 'efficientnet_b2',\n",
       " 'efficientnet_b2_pruned',\n",
       " 'efficientnet_b2a',\n",
       " 'efficientnet_b3',\n",
       " 'efficientnet_b3_g8_gn',\n",
       " 'efficientnet_b3_gn',\n",
       " 'efficientnet_b3_pruned',\n",
       " 'efficientnet_b3a',\n",
       " 'efficientnet_b4',\n",
       " 'efficientnet_b5',\n",
       " 'efficientnet_b6',\n",
       " 'efficientnet_b7',\n",
       " 'efficientnet_b8',\n",
       " 'efficientnet_cc_b0_4e',\n",
       " 'efficientnet_cc_b0_8e',\n",
       " 'efficientnet_cc_b1_8e',\n",
       " 'efficientnet_el',\n",
       " 'efficientnet_el_pruned',\n",
       " 'efficientnet_em',\n",
       " 'efficientnet_es',\n",
       " 'efficientnet_es_pruned',\n",
       " 'efficientnet_l2',\n",
       " 'efficientnet_lite0',\n",
       " 'efficientnet_lite1',\n",
       " 'efficientnet_lite2',\n",
       " 'efficientnet_lite3',\n",
       " 'efficientnet_lite4',\n",
       " 'efficientnetv2_l',\n",
       " 'efficientnetv2_m',\n",
       " 'efficientnetv2_rw_m',\n",
       " 'efficientnetv2_rw_s',\n",
       " 'efficientnetv2_rw_t',\n",
       " 'efficientnetv2_s',\n",
       " 'efficientnetv2_xl',\n",
       " 'ens_adv_inception_resnet_v2',\n",
       " 'ese_vovnet19b_dw',\n",
       " 'ese_vovnet19b_slim',\n",
       " 'ese_vovnet19b_slim_dw',\n",
       " 'ese_vovnet39b',\n",
       " 'ese_vovnet39b_evos',\n",
       " 'ese_vovnet57b',\n",
       " 'ese_vovnet99b',\n",
       " 'ese_vovnet99b_iabn',\n",
       " 'fbnetc_100',\n",
       " 'fbnetv3_b',\n",
       " 'fbnetv3_d',\n",
       " 'fbnetv3_g',\n",
       " 'gc_efficientnetv2_rw_t',\n",
       " 'gcresnet33ts',\n",
       " 'gcresnet50t',\n",
       " 'gcresnext26ts',\n",
       " 'gcresnext50ts',\n",
       " 'gcvit_base',\n",
       " 'gcvit_small',\n",
       " 'gcvit_tiny',\n",
       " 'gcvit_xtiny',\n",
       " 'gcvit_xxtiny',\n",
       " 'gernet_l',\n",
       " 'gernet_m',\n",
       " 'gernet_s',\n",
       " 'ghostnet_050',\n",
       " 'ghostnet_100',\n",
       " 'ghostnet_130',\n",
       " 'gluon_inception_v3',\n",
       " 'gluon_resnet18_v1b',\n",
       " 'gluon_resnet34_v1b',\n",
       " 'gluon_resnet50_v1b',\n",
       " 'gluon_resnet50_v1c',\n",
       " 'gluon_resnet50_v1d',\n",
       " 'gluon_resnet50_v1s',\n",
       " 'gluon_resnet101_v1b',\n",
       " 'gluon_resnet101_v1c',\n",
       " 'gluon_resnet101_v1d',\n",
       " 'gluon_resnet101_v1s',\n",
       " 'gluon_resnet152_v1b',\n",
       " 'gluon_resnet152_v1c',\n",
       " 'gluon_resnet152_v1d',\n",
       " 'gluon_resnet152_v1s',\n",
       " 'gluon_resnext50_32x4d',\n",
       " 'gluon_resnext101_32x4d',\n",
       " 'gluon_resnext101_64x4d',\n",
       " 'gluon_senet154',\n",
       " 'gluon_seresnext50_32x4d',\n",
       " 'gluon_seresnext101_32x4d',\n",
       " 'gluon_seresnext101_64x4d',\n",
       " 'gluon_xception65',\n",
       " 'gmixer_12_224',\n",
       " 'gmixer_24_224',\n",
       " 'gmlp_b16_224',\n",
       " 'gmlp_s16_224',\n",
       " 'gmlp_ti16_224',\n",
       " 'halo2botnet50ts_256',\n",
       " 'halonet26t',\n",
       " 'halonet50ts',\n",
       " 'halonet_h1',\n",
       " 'haloregnetz_b',\n",
       " 'hardcorenas_a',\n",
       " 'hardcorenas_b',\n",
       " 'hardcorenas_c',\n",
       " 'hardcorenas_d',\n",
       " 'hardcorenas_e',\n",
       " 'hardcorenas_f',\n",
       " 'hrnet_w18',\n",
       " 'hrnet_w18_small',\n",
       " 'hrnet_w18_small_v2',\n",
       " 'hrnet_w30',\n",
       " 'hrnet_w32',\n",
       " 'hrnet_w40',\n",
       " 'hrnet_w44',\n",
       " 'hrnet_w48',\n",
       " 'hrnet_w64',\n",
       " 'ig_resnext101_32x8d',\n",
       " 'ig_resnext101_32x16d',\n",
       " 'ig_resnext101_32x32d',\n",
       " 'ig_resnext101_32x48d',\n",
       " 'inception_resnet_v2',\n",
       " 'inception_v3',\n",
       " 'inception_v4',\n",
       " 'jx_nest_base',\n",
       " 'jx_nest_small',\n",
       " 'jx_nest_tiny',\n",
       " 'lambda_resnet26rpt_256',\n",
       " 'lambda_resnet26t',\n",
       " 'lambda_resnet50ts',\n",
       " 'lamhalobotnet50ts_256',\n",
       " 'lcnet_035',\n",
       " 'lcnet_050',\n",
       " 'lcnet_075',\n",
       " 'lcnet_100',\n",
       " 'lcnet_150',\n",
       " 'legacy_senet154',\n",
       " 'legacy_seresnet18',\n",
       " 'legacy_seresnet34',\n",
       " 'legacy_seresnet50',\n",
       " 'legacy_seresnet101',\n",
       " 'legacy_seresnet152',\n",
       " 'legacy_seresnext26_32x4d',\n",
       " 'legacy_seresnext50_32x4d',\n",
       " 'legacy_seresnext101_32x4d',\n",
       " 'levit_128',\n",
       " 'levit_128s',\n",
       " 'levit_192',\n",
       " 'levit_256',\n",
       " 'levit_256d',\n",
       " 'levit_384',\n",
       " 'maxvit_base_224',\n",
       " 'maxvit_large_224',\n",
       " 'maxvit_nano_rw_256',\n",
       " 'maxvit_pico_rw_256',\n",
       " 'maxvit_rmlp_nano_rw_256',\n",
       " 'maxvit_rmlp_pico_rw_256',\n",
       " 'maxvit_rmlp_small_rw_224',\n",
       " 'maxvit_rmlp_small_rw_256',\n",
       " 'maxvit_rmlp_tiny_rw_256',\n",
       " 'maxvit_small_224',\n",
       " 'maxvit_tiny_224',\n",
       " 'maxvit_tiny_pm_256',\n",
       " 'maxvit_tiny_rw_224',\n",
       " 'maxvit_tiny_rw_256',\n",
       " 'maxvit_xlarge_224',\n",
       " 'maxxvit_rmlp_nano_rw_256',\n",
       " 'maxxvit_rmlp_small_rw_256',\n",
       " 'maxxvit_rmlp_tiny_rw_256',\n",
       " 'mixer_b16_224',\n",
       " 'mixer_b16_224_in21k',\n",
       " 'mixer_b16_224_miil',\n",
       " 'mixer_b16_224_miil_in21k',\n",
       " 'mixer_b32_224',\n",
       " 'mixer_l16_224',\n",
       " 'mixer_l16_224_in21k',\n",
       " 'mixer_l32_224',\n",
       " 'mixer_s16_224',\n",
       " 'mixer_s32_224',\n",
       " 'mixnet_l',\n",
       " 'mixnet_m',\n",
       " 'mixnet_s',\n",
       " 'mixnet_xl',\n",
       " 'mixnet_xxl',\n",
       " 'mnasnet_050',\n",
       " 'mnasnet_075',\n",
       " 'mnasnet_100',\n",
       " 'mnasnet_140',\n",
       " 'mnasnet_a1',\n",
       " 'mnasnet_b1',\n",
       " 'mnasnet_small',\n",
       " 'mobilenetv2_035',\n",
       " 'mobilenetv2_050',\n",
       " 'mobilenetv2_075',\n",
       " 'mobilenetv2_100',\n",
       " 'mobilenetv2_110d',\n",
       " 'mobilenetv2_120d',\n",
       " 'mobilenetv2_140',\n",
       " 'mobilenetv3_large_075',\n",
       " 'mobilenetv3_large_100',\n",
       " 'mobilenetv3_large_100_miil',\n",
       " 'mobilenetv3_large_100_miil_in21k',\n",
       " 'mobilenetv3_rw',\n",
       " 'mobilenetv3_small_050',\n",
       " 'mobilenetv3_small_075',\n",
       " 'mobilenetv3_small_100',\n",
       " 'mobilevit_s',\n",
       " 'mobilevit_xs',\n",
       " 'mobilevit_xxs',\n",
       " 'mobilevitv2_050',\n",
       " 'mobilevitv2_075',\n",
       " 'mobilevitv2_100',\n",
       " 'mobilevitv2_125',\n",
       " 'mobilevitv2_150',\n",
       " 'mobilevitv2_150_384_in22ft1k',\n",
       " 'mobilevitv2_150_in22ft1k',\n",
       " 'mobilevitv2_175',\n",
       " 'mobilevitv2_175_384_in22ft1k',\n",
       " 'mobilevitv2_175_in22ft1k',\n",
       " 'mobilevitv2_200',\n",
       " 'mobilevitv2_200_384_in22ft1k',\n",
       " 'mobilevitv2_200_in22ft1k',\n",
       " 'mvitv2_base',\n",
       " 'mvitv2_large',\n",
       " 'mvitv2_small',\n",
       " 'mvitv2_small_cls',\n",
       " 'mvitv2_tiny',\n",
       " 'nasnetalarge',\n",
       " 'nest_base',\n",
       " 'nest_small',\n",
       " 'nest_tiny',\n",
       " 'nf_ecaresnet26',\n",
       " 'nf_ecaresnet50',\n",
       " 'nf_ecaresnet101',\n",
       " 'nf_regnet_b0',\n",
       " 'nf_regnet_b1',\n",
       " 'nf_regnet_b2',\n",
       " 'nf_regnet_b3',\n",
       " 'nf_regnet_b4',\n",
       " 'nf_regnet_b5',\n",
       " 'nf_resnet26',\n",
       " 'nf_resnet50',\n",
       " 'nf_resnet101',\n",
       " 'nf_seresnet26',\n",
       " 'nf_seresnet50',\n",
       " 'nf_seresnet101',\n",
       " 'nfnet_f0',\n",
       " 'nfnet_f1',\n",
       " 'nfnet_f2',\n",
       " 'nfnet_f3',\n",
       " 'nfnet_f4',\n",
       " 'nfnet_f5',\n",
       " 'nfnet_f6',\n",
       " 'nfnet_f7',\n",
       " 'nfnet_l0',\n",
       " 'pit_b_224',\n",
       " 'pit_b_distilled_224',\n",
       " 'pit_s_224',\n",
       " 'pit_s_distilled_224',\n",
       " 'pit_ti_224',\n",
       " 'pit_ti_distilled_224',\n",
       " 'pit_xs_224',\n",
       " 'pit_xs_distilled_224',\n",
       " 'pnasnet5large',\n",
       " 'poolformer_m36',\n",
       " 'poolformer_m48',\n",
       " 'poolformer_s12',\n",
       " 'poolformer_s24',\n",
       " 'poolformer_s36',\n",
       " 'pvt_v2_b0',\n",
       " 'pvt_v2_b1',\n",
       " 'pvt_v2_b2',\n",
       " 'pvt_v2_b2_li',\n",
       " 'pvt_v2_b3',\n",
       " 'pvt_v2_b4',\n",
       " 'pvt_v2_b5',\n",
       " 'regnetv_040',\n",
       " 'regnetv_064',\n",
       " 'regnetx_002',\n",
       " 'regnetx_004',\n",
       " 'regnetx_006',\n",
       " 'regnetx_008',\n",
       " 'regnetx_016',\n",
       " 'regnetx_032',\n",
       " 'regnetx_040',\n",
       " 'regnetx_064',\n",
       " 'regnetx_080',\n",
       " 'regnetx_120',\n",
       " 'regnetx_160',\n",
       " 'regnetx_320',\n",
       " 'regnety_002',\n",
       " 'regnety_004',\n",
       " 'regnety_006',\n",
       " 'regnety_008',\n",
       " 'regnety_016',\n",
       " 'regnety_032',\n",
       " 'regnety_040',\n",
       " 'regnety_040s_gn',\n",
       " 'regnety_064',\n",
       " 'regnety_080',\n",
       " 'regnety_120',\n",
       " 'regnety_160',\n",
       " 'regnety_320',\n",
       " 'regnetz_005',\n",
       " 'regnetz_040',\n",
       " 'regnetz_040h',\n",
       " 'regnetz_b16',\n",
       " 'regnetz_b16_evos',\n",
       " 'regnetz_c16',\n",
       " 'regnetz_c16_evos',\n",
       " 'regnetz_d8',\n",
       " 'regnetz_d8_evos',\n",
       " 'regnetz_d32',\n",
       " 'regnetz_e8',\n",
       " 'repvgg_a2',\n",
       " 'repvgg_b0',\n",
       " 'repvgg_b1',\n",
       " 'repvgg_b1g4',\n",
       " 'repvgg_b2',\n",
       " 'repvgg_b2g4',\n",
       " 'repvgg_b3',\n",
       " 'repvgg_b3g4',\n",
       " 'res2net50_14w_8s',\n",
       " 'res2net50_26w_4s',\n",
       " 'res2net50_26w_6s',\n",
       " 'res2net50_26w_8s',\n",
       " 'res2net50_48w_2s',\n",
       " 'res2net101_26w_4s',\n",
       " 'res2next50',\n",
       " 'resmlp_12_224',\n",
       " 'resmlp_12_224_dino',\n",
       " 'resmlp_12_distilled_224',\n",
       " 'resmlp_24_224',\n",
       " 'resmlp_24_224_dino',\n",
       " 'resmlp_24_distilled_224',\n",
       " 'resmlp_36_224',\n",
       " 'resmlp_36_distilled_224',\n",
       " 'resmlp_big_24_224',\n",
       " 'resmlp_big_24_224_in22ft1k',\n",
       " 'resmlp_big_24_distilled_224',\n",
       " 'resnest14d',\n",
       " 'resnest26d',\n",
       " 'resnest50d',\n",
       " 'resnest50d_1s4x24d',\n",
       " 'resnest50d_4s2x40d',\n",
       " 'resnest101e',\n",
       " 'resnest200e',\n",
       " 'resnest269e',\n",
       " 'resnet10t',\n",
       " 'resnet14t',\n",
       " 'resnet18',\n",
       " 'resnet18d',\n",
       " 'resnet26',\n",
       " 'resnet26d',\n",
       " 'resnet26t',\n",
       " 'resnet32ts',\n",
       " 'resnet33ts',\n",
       " 'resnet34',\n",
       " 'resnet34d',\n",
       " 'resnet50',\n",
       " 'resnet50_gn',\n",
       " 'resnet50d',\n",
       " 'resnet50t',\n",
       " 'resnet51q',\n",
       " 'resnet61q',\n",
       " 'resnet101',\n",
       " 'resnet101d',\n",
       " 'resnet152',\n",
       " 'resnet152d',\n",
       " 'resnet200',\n",
       " 'resnet200d',\n",
       " 'resnetaa50',\n",
       " 'resnetaa50d',\n",
       " 'resnetaa101d',\n",
       " 'resnetblur18',\n",
       " 'resnetblur50',\n",
       " 'resnetblur50d',\n",
       " 'resnetblur101d',\n",
       " 'resnetrs50',\n",
       " 'resnetrs101',\n",
       " 'resnetrs152',\n",
       " 'resnetrs200',\n",
       " 'resnetrs270',\n",
       " 'resnetrs350',\n",
       " 'resnetrs420',\n",
       " 'resnetv2_50',\n",
       " 'resnetv2_50d',\n",
       " 'resnetv2_50d_evob',\n",
       " 'resnetv2_50d_evos',\n",
       " 'resnetv2_50d_frn',\n",
       " 'resnetv2_50d_gn',\n",
       " 'resnetv2_50t',\n",
       " 'resnetv2_50x1_bit_distilled',\n",
       " 'resnetv2_50x1_bitm',\n",
       " 'resnetv2_50x1_bitm_in21k',\n",
       " 'resnetv2_50x3_bitm',\n",
       " 'resnetv2_50x3_bitm_in21k',\n",
       " 'resnetv2_101',\n",
       " 'resnetv2_101d',\n",
       " 'resnetv2_101x1_bitm',\n",
       " 'resnetv2_101x1_bitm_in21k',\n",
       " 'resnetv2_101x3_bitm',\n",
       " 'resnetv2_101x3_bitm_in21k',\n",
       " 'resnetv2_152',\n",
       " 'resnetv2_152d',\n",
       " 'resnetv2_152x2_bit_teacher',\n",
       " 'resnetv2_152x2_bit_teacher_384',\n",
       " 'resnetv2_152x2_bitm',\n",
       " 'resnetv2_152x2_bitm_in21k',\n",
       " 'resnetv2_152x4_bitm',\n",
       " 'resnetv2_152x4_bitm_in21k',\n",
       " 'resnext26ts',\n",
       " 'resnext50_32x4d',\n",
       " 'resnext50d_32x4d',\n",
       " 'resnext101_32x4d',\n",
       " 'resnext101_32x8d',\n",
       " 'resnext101_64x4d',\n",
       " 'rexnet_100',\n",
       " 'rexnet_130',\n",
       " 'rexnet_150',\n",
       " 'rexnet_200',\n",
       " 'rexnetr_100',\n",
       " 'rexnetr_130',\n",
       " 'rexnetr_150',\n",
       " 'rexnetr_200',\n",
       " 'sebotnet33ts_256',\n",
       " 'sedarknet21',\n",
       " 'sehalonet33ts',\n",
       " 'selecsls42',\n",
       " 'selecsls42b',\n",
       " 'selecsls60',\n",
       " 'selecsls60b',\n",
       " 'selecsls84',\n",
       " 'semnasnet_050',\n",
       " 'semnasnet_075',\n",
       " 'semnasnet_100',\n",
       " 'semnasnet_140',\n",
       " 'semobilevit_s',\n",
       " 'senet154',\n",
       " 'sequencer2d_l',\n",
       " 'sequencer2d_m',\n",
       " 'sequencer2d_s',\n",
       " 'seresnet18',\n",
       " 'seresnet33ts',\n",
       " 'seresnet34',\n",
       " 'seresnet50',\n",
       " 'seresnet50t',\n",
       " 'seresnet101',\n",
       " 'seresnet152',\n",
       " 'seresnet152d',\n",
       " 'seresnet200d',\n",
       " 'seresnet269d',\n",
       " 'seresnetaa50d',\n",
       " 'seresnext26d_32x4d',\n",
       " 'seresnext26t_32x4d',\n",
       " 'seresnext26tn_32x4d',\n",
       " 'seresnext26ts',\n",
       " 'seresnext50_32x4d',\n",
       " 'seresnext101_32x4d',\n",
       " 'seresnext101_32x8d',\n",
       " 'seresnext101d_32x8d',\n",
       " 'seresnextaa101d_32x8d',\n",
       " 'skresnet18',\n",
       " 'skresnet34',\n",
       " 'skresnet50',\n",
       " 'skresnet50d',\n",
       " 'skresnext50_32x4d',\n",
       " 'spnasnet_100',\n",
       " 'ssl_resnet18',\n",
       " 'ssl_resnet50',\n",
       " 'ssl_resnext50_32x4d',\n",
       " 'ssl_resnext101_32x4d',\n",
       " 'ssl_resnext101_32x8d',\n",
       " 'ssl_resnext101_32x16d',\n",
       " 'swin_base_patch4_window7_224',\n",
       " 'swin_base_patch4_window7_224_in22k',\n",
       " 'swin_base_patch4_window12_384',\n",
       " 'swin_base_patch4_window12_384_in22k',\n",
       " 'swin_large_patch4_window7_224',\n",
       " 'swin_large_patch4_window7_224_in22k',\n",
       " 'swin_large_patch4_window12_384',\n",
       " 'swin_large_patch4_window12_384_in22k',\n",
       " 'swin_s3_base_224',\n",
       " 'swin_s3_small_224',\n",
       " 'swin_s3_tiny_224',\n",
       " 'swin_small_patch4_window7_224',\n",
       " 'swin_tiny_patch4_window7_224',\n",
       " 'swinv2_base_window8_256',\n",
       " 'swinv2_base_window12_192_22k',\n",
       " 'swinv2_base_window12to16_192to256_22kft1k',\n",
       " 'swinv2_base_window12to24_192to384_22kft1k',\n",
       " 'swinv2_base_window16_256',\n",
       " 'swinv2_cr_base_224',\n",
       " 'swinv2_cr_base_384',\n",
       " 'swinv2_cr_base_ns_224',\n",
       " 'swinv2_cr_giant_224',\n",
       " 'swinv2_cr_giant_384',\n",
       " 'swinv2_cr_huge_224',\n",
       " 'swinv2_cr_huge_384',\n",
       " 'swinv2_cr_large_224',\n",
       " 'swinv2_cr_large_384',\n",
       " 'swinv2_cr_small_224',\n",
       " 'swinv2_cr_small_384',\n",
       " 'swinv2_cr_small_ns_224',\n",
       " 'swinv2_cr_tiny_224',\n",
       " 'swinv2_cr_tiny_384',\n",
       " 'swinv2_cr_tiny_ns_224',\n",
       " 'swinv2_large_window12_192_22k',\n",
       " 'swinv2_large_window12to16_192to256_22kft1k',\n",
       " 'swinv2_large_window12to24_192to384_22kft1k',\n",
       " 'swinv2_small_window8_256',\n",
       " 'swinv2_small_window16_256',\n",
       " 'swinv2_tiny_window8_256',\n",
       " 'swinv2_tiny_window16_256',\n",
       " 'swsl_resnet18',\n",
       " 'swsl_resnet50',\n",
       " 'swsl_resnext50_32x4d',\n",
       " 'swsl_resnext101_32x4d',\n",
       " 'swsl_resnext101_32x8d',\n",
       " 'swsl_resnext101_32x16d',\n",
       " 'tf_efficientnet_b0',\n",
       " 'tf_efficientnet_b0_ap',\n",
       " 'tf_efficientnet_b0_ns',\n",
       " 'tf_efficientnet_b1',\n",
       " 'tf_efficientnet_b1_ap',\n",
       " 'tf_efficientnet_b1_ns',\n",
       " 'tf_efficientnet_b2',\n",
       " 'tf_efficientnet_b2_ap',\n",
       " 'tf_efficientnet_b2_ns',\n",
       " 'tf_efficientnet_b3',\n",
       " 'tf_efficientnet_b3_ap',\n",
       " 'tf_efficientnet_b3_ns',\n",
       " 'tf_efficientnet_b4',\n",
       " 'tf_efficientnet_b4_ap',\n",
       " 'tf_efficientnet_b4_ns',\n",
       " 'tf_efficientnet_b5',\n",
       " 'tf_efficientnet_b5_ap',\n",
       " 'tf_efficientnet_b5_ns',\n",
       " 'tf_efficientnet_b6',\n",
       " 'tf_efficientnet_b6_ap',\n",
       " 'tf_efficientnet_b6_ns',\n",
       " 'tf_efficientnet_b7',\n",
       " 'tf_efficientnet_b7_ap',\n",
       " 'tf_efficientnet_b7_ns',\n",
       " 'tf_efficientnet_b8',\n",
       " 'tf_efficientnet_b8_ap',\n",
       " 'tf_efficientnet_cc_b0_4e',\n",
       " 'tf_efficientnet_cc_b0_8e',\n",
       " 'tf_efficientnet_cc_b1_8e',\n",
       " 'tf_efficientnet_el',\n",
       " 'tf_efficientnet_em',\n",
       " 'tf_efficientnet_es',\n",
       " 'tf_efficientnet_l2_ns',\n",
       " 'tf_efficientnet_l2_ns_475',\n",
       " 'tf_efficientnet_lite0',\n",
       " 'tf_efficientnet_lite1',\n",
       " 'tf_efficientnet_lite2',\n",
       " 'tf_efficientnet_lite3',\n",
       " 'tf_efficientnet_lite4',\n",
       " 'tf_efficientnetv2_b0',\n",
       " 'tf_efficientnetv2_b1',\n",
       " 'tf_efficientnetv2_b2',\n",
       " 'tf_efficientnetv2_b3',\n",
       " 'tf_efficientnetv2_l',\n",
       " 'tf_efficientnetv2_l_in21ft1k',\n",
       " 'tf_efficientnetv2_l_in21k',\n",
       " 'tf_efficientnetv2_m',\n",
       " 'tf_efficientnetv2_m_in21ft1k',\n",
       " 'tf_efficientnetv2_m_in21k',\n",
       " 'tf_efficientnetv2_s',\n",
       " 'tf_efficientnetv2_s_in21ft1k',\n",
       " 'tf_efficientnetv2_s_in21k',\n",
       " 'tf_efficientnetv2_xl_in21ft1k',\n",
       " 'tf_efficientnetv2_xl_in21k',\n",
       " 'tf_inception_v3',\n",
       " 'tf_mixnet_l',\n",
       " 'tf_mixnet_m',\n",
       " 'tf_mixnet_s',\n",
       " 'tf_mobilenetv3_large_075',\n",
       " 'tf_mobilenetv3_large_100',\n",
       " 'tf_mobilenetv3_large_minimal_100',\n",
       " 'tf_mobilenetv3_small_075',\n",
       " 'tf_mobilenetv3_small_100',\n",
       " 'tf_mobilenetv3_small_minimal_100',\n",
       " 'tinynet_a',\n",
       " 'tinynet_b',\n",
       " 'tinynet_c',\n",
       " 'tinynet_d',\n",
       " 'tinynet_e',\n",
       " 'tnt_b_patch16_224',\n",
       " 'tnt_s_patch16_224',\n",
       " 'tresnet_l',\n",
       " 'tresnet_l_448',\n",
       " 'tresnet_m',\n",
       " 'tresnet_m_448',\n",
       " 'tresnet_m_miil_in21k',\n",
       " 'tresnet_v2_l',\n",
       " 'tresnet_xl',\n",
       " 'tresnet_xl_448',\n",
       " 'tv_densenet121',\n",
       " 'tv_resnet34',\n",
       " 'tv_resnet50',\n",
       " 'tv_resnet101',\n",
       " 'tv_resnet152',\n",
       " 'tv_resnext50_32x4d',\n",
       " 'twins_pcpvt_base',\n",
       " 'twins_pcpvt_large',\n",
       " 'twins_pcpvt_small',\n",
       " 'twins_svt_base',\n",
       " 'twins_svt_large',\n",
       " 'twins_svt_small',\n",
       " 'vgg11',\n",
       " 'vgg11_bn',\n",
       " 'vgg13',\n",
       " 'vgg13_bn',\n",
       " 'vgg16',\n",
       " 'vgg16_bn',\n",
       " 'vgg19',\n",
       " 'vgg19_bn',\n",
       " 'visformer_small',\n",
       " 'visformer_tiny',\n",
       " 'vit_base_patch8_224',\n",
       " 'vit_base_patch8_224_dino',\n",
       " 'vit_base_patch8_224_in21k',\n",
       " 'vit_base_patch16_18x2_224',\n",
       " 'vit_base_patch16_224',\n",
       " 'vit_base_patch16_224_dino',\n",
       " 'vit_base_patch16_224_in21k',\n",
       " 'vit_base_patch16_224_miil',\n",
       " 'vit_base_patch16_224_miil_in21k',\n",
       " 'vit_base_patch16_224_sam',\n",
       " 'vit_base_patch16_384',\n",
       " 'vit_base_patch16_plus_240',\n",
       " 'vit_base_patch16_rpn_224',\n",
       " 'vit_base_patch32_224',\n",
       " 'vit_base_patch32_224_clip_laion2b',\n",
       " 'vit_base_patch32_224_in21k',\n",
       " 'vit_base_patch32_224_sam',\n",
       " 'vit_base_patch32_384',\n",
       " 'vit_base_patch32_plus_256',\n",
       " 'vit_base_r26_s32_224',\n",
       " 'vit_base_r50_s16_224',\n",
       " 'vit_base_r50_s16_224_in21k',\n",
       " 'vit_base_r50_s16_384',\n",
       " 'vit_base_resnet26d_224',\n",
       " 'vit_base_resnet50_224_in21k',\n",
       " 'vit_base_resnet50_384',\n",
       " 'vit_base_resnet50d_224',\n",
       " 'vit_giant_patch14_224',\n",
       " 'vit_giant_patch14_224_clip_laion2b',\n",
       " 'vit_gigantic_patch14_224',\n",
       " 'vit_huge_patch14_224',\n",
       " 'vit_huge_patch14_224_clip_laion2b',\n",
       " 'vit_huge_patch14_224_in21k',\n",
       " 'vit_large_patch14_224',\n",
       " 'vit_large_patch14_224_clip_laion2b',\n",
       " 'vit_large_patch16_224',\n",
       " 'vit_large_patch16_224_in21k',\n",
       " 'vit_large_patch16_384',\n",
       " 'vit_large_patch32_224',\n",
       " 'vit_large_patch32_224_in21k',\n",
       " 'vit_large_patch32_384',\n",
       " 'vit_large_r50_s32_224',\n",
       " 'vit_large_r50_s32_224_in21k',\n",
       " 'vit_large_r50_s32_384',\n",
       " 'vit_relpos_base_patch16_224',\n",
       " 'vit_relpos_base_patch16_cls_224',\n",
       " 'vit_relpos_base_patch16_clsgap_224',\n",
       " 'vit_relpos_base_patch16_plus_240',\n",
       " 'vit_relpos_base_patch16_rpn_224',\n",
       " 'vit_relpos_base_patch32_plus_rpn_256',\n",
       " 'vit_relpos_medium_patch16_224',\n",
       " 'vit_relpos_medium_patch16_cls_224',\n",
       " 'vit_relpos_medium_patch16_rpn_224',\n",
       " 'vit_relpos_small_patch16_224',\n",
       " 'vit_relpos_small_patch16_rpn_224',\n",
       " 'vit_small_patch8_224_dino',\n",
       " 'vit_small_patch16_18x2_224',\n",
       " 'vit_small_patch16_36x1_224',\n",
       " 'vit_small_patch16_224',\n",
       " 'vit_small_patch16_224_dino',\n",
       " 'vit_small_patch16_224_in21k',\n",
       " 'vit_small_patch16_384',\n",
       " 'vit_small_patch32_224',\n",
       " 'vit_small_patch32_224_in21k',\n",
       " 'vit_small_patch32_384',\n",
       " 'vit_small_r26_s32_224',\n",
       " 'vit_small_r26_s32_224_in21k',\n",
       " 'vit_small_r26_s32_384',\n",
       " 'vit_small_resnet26d_224',\n",
       " 'vit_small_resnet50d_s16_224',\n",
       " 'vit_srelpos_medium_patch16_224',\n",
       " 'vit_srelpos_small_patch16_224',\n",
       " 'vit_tiny_patch16_224',\n",
       " 'vit_tiny_patch16_224_in21k',\n",
       " 'vit_tiny_patch16_384',\n",
       " 'vit_tiny_r_s16_p8_224',\n",
       " 'vit_tiny_r_s16_p8_224_in21k',\n",
       " 'vit_tiny_r_s16_p8_384',\n",
       " 'volo_d1_224',\n",
       " 'volo_d1_384',\n",
       " 'volo_d2_224',\n",
       " 'volo_d2_384',\n",
       " 'volo_d3_224',\n",
       " 'volo_d3_448',\n",
       " 'volo_d4_224',\n",
       " 'volo_d4_448',\n",
       " 'volo_d5_224',\n",
       " 'volo_d5_448',\n",
       " 'volo_d5_512',\n",
       " 'vovnet39a',\n",
       " 'vovnet57a',\n",
       " 'wide_resnet50_2',\n",
       " 'wide_resnet101_2',\n",
       " 'xception',\n",
       " 'xception41',\n",
       " 'xception41p',\n",
       " 'xception65',\n",
       " 'xception65p',\n",
       " 'xception71',\n",
       " 'xcit_large_24_p8_224',\n",
       " 'xcit_large_24_p8_224_dist',\n",
       " 'xcit_large_24_p8_384_dist',\n",
       " 'xcit_large_24_p16_224',\n",
       " 'xcit_large_24_p16_224_dist',\n",
       " 'xcit_large_24_p16_384_dist',\n",
       " 'xcit_medium_24_p8_224',\n",
       " 'xcit_medium_24_p8_224_dist',\n",
       " 'xcit_medium_24_p8_384_dist',\n",
       " 'xcit_medium_24_p16_224',\n",
       " 'xcit_medium_24_p16_224_dist',\n",
       " 'xcit_medium_24_p16_384_dist',\n",
       " 'xcit_nano_12_p8_224',\n",
       " 'xcit_nano_12_p8_224_dist',\n",
       " 'xcit_nano_12_p8_384_dist',\n",
       " 'xcit_nano_12_p16_224',\n",
       " 'xcit_nano_12_p16_224_dist',\n",
       " 'xcit_nano_12_p16_384_dist',\n",
       " 'xcit_small_12_p8_224',\n",
       " 'xcit_small_12_p8_224_dist',\n",
       " 'xcit_small_12_p8_384_dist',\n",
       " 'xcit_small_12_p16_224',\n",
       " 'xcit_small_12_p16_224_dist',\n",
       " 'xcit_small_12_p16_384_dist',\n",
       " 'xcit_small_24_p8_224',\n",
       " 'xcit_small_24_p8_224_dist',\n",
       " 'xcit_small_24_p8_384_dist',\n",
       " 'xcit_small_24_p16_224',\n",
       " 'xcit_small_24_p16_224_dist',\n",
       " 'xcit_small_24_p16_384_dist',\n",
       " 'xcit_tiny_12_p8_224',\n",
       " 'xcit_tiny_12_p8_224_dist',\n",
       " 'xcit_tiny_12_p8_384_dist',\n",
       " 'xcit_tiny_12_p16_224',\n",
       " 'xcit_tiny_12_p16_224_dist',\n",
       " 'xcit_tiny_12_p16_384_dist',\n",
       " 'xcit_tiny_24_p8_224',\n",
       " 'xcit_tiny_24_p8_224_dist',\n",
       " 'xcit_tiny_24_p8_384_dist',\n",
       " 'xcit_tiny_24_p16_224',\n",
       " 'xcit_tiny_24_p16_224_dist',\n",
       " 'xcit_tiny_24_p16_384_dist']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import timm\n",
    "timm.list_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d88d0b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Oleg\\anaconda3\\lib\\site-packages\\torch\\functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\TensorShape.cpp:3484.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SwinTransformer(\n",
      "  (patch_embed): PatchEmbed(\n",
      "    (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
      "    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "  (layers): Sequential(\n",
      "    (0): BasicLayer(\n",
      "      (blocks): Sequential(\n",
      "        (0): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.009)\n",
      "          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (downsample): PatchMerging(\n",
      "        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (reduction): Linear(in_features=384, out_features=192, bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicLayer(\n",
      "      (blocks): Sequential(\n",
      "        (0): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.018)\n",
      "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.027)\n",
      "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (downsample): PatchMerging(\n",
      "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (reduction): Linear(in_features=768, out_features=384, bias=False)\n",
      "      )\n",
      "    )\n",
      "    (2): BasicLayer(\n",
      "      (blocks): Sequential(\n",
      "        (0): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.036)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.045)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.055)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.064)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.073)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.082)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (downsample): PatchMerging(\n",
      "        (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
      "        (reduction): Linear(in_features=1536, out_features=768, bias=False)\n",
      "      )\n",
      "    )\n",
      "    (3): BasicLayer(\n",
      "      (blocks): Sequential(\n",
      "        (0): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.091)\n",
      "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.100)\n",
      "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (head): Linear(in_features=768, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model=timm.create_model('swin_s3_tiny_224', pretrained=True) \n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7bec945f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SwinTransformer(\n",
      "  (patch_embed): PatchEmbed(\n",
      "    (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
      "    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "  (layers): Sequential(\n",
      "    (0): BasicLayer(\n",
      "      (blocks): Sequential(\n",
      "        (0): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.009)\n",
      "          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (downsample): PatchMerging(\n",
      "        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (reduction): Linear(in_features=384, out_features=192, bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicLayer(\n",
      "      (blocks): Sequential(\n",
      "        (0): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.018)\n",
      "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.027)\n",
      "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (downsample): PatchMerging(\n",
      "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (reduction): Linear(in_features=768, out_features=384, bias=False)\n",
      "      )\n",
      "    )\n",
      "    (2): BasicLayer(\n",
      "      (blocks): Sequential(\n",
      "        (0): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.036)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.045)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.055)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.064)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.073)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.082)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (downsample): PatchMerging(\n",
      "        (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
      "        (reduction): Linear(in_features=1536, out_features=768, bias=False)\n",
      "      )\n",
      "    )\n",
      "    (3): BasicLayer(\n",
      "      (blocks): Sequential(\n",
      "        (0): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.091)\n",
      "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.100)\n",
      "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (head): Linear(in_features=768, out_features=257, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model.head=nn.Linear(in_features=768, out_features=num_classes)\n",
    "model=model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "315ee0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 257])\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    img = torch.randn(1, 3, 224, 224).to(device)\n",
    "    model=model.to(device)\n",
    "    model.eval()\n",
    "    f=model.forward(img)\n",
    "    print(f.shape)\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a96a6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, requires_grad):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8889efce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b86feeb5641c4c6b9749fcadf6d629f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1333 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1 - loss : 0.2595 - acc: 0.4730 - val_loss : 0.0816 - val_acc: 0.3570\n",
      "\n",
      "Best acc:0.3569834232330322\n",
      "val_loss : 0.0816 - val_acc: 0.3570\n",
      "\n"
     ]
    }
   ],
   "source": [
    "set_parameter_requires_grad(model, requires_grad=False)\n",
    "set_parameter_requires_grad(model.head, requires_grad=True)\n",
    "train(model,1,0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "808a15bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ecc1cd6371846ddb91a9f7ee07e1dda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1333 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1 - loss : 0.0723 - acc: 0.7316 - val_loss : 0.0187 - val_acc: 0.4019\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "287a92e3e1a645cba30cde9dd48c7879",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1333 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 2 - loss : 0.0495 - acc: 0.8088 - val_loss : 0.0172 - val_acc: 0.4085\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2669e0fd865d410e995a8a709dfebc39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1333 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 3 - loss : 0.0414 - acc: 0.8366 - val_loss : 0.0171 - val_acc: 0.4125\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5a3ba55e1634779b9d8c1e1c64ef499",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1333 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 4 - loss : 0.0391 - acc: 0.8449 - val_loss : 0.0182 - val_acc: 0.4125\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "285e8e6a4ed74921b4b035e8bcae2d4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1333 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 5 - loss : 0.0331 - acc: 0.8671 - val_loss : 0.0184 - val_acc: 0.4083\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f70ee1d8e4ef44e3b61e5fd837fd843e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1333 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 6 - loss : 0.0310 - acc: 0.8760 - val_loss : 0.0186 - val_acc: 0.4106\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e266f8db62434e9abe698bc18635ba6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1333 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 7 - loss : 0.0301 - acc: 0.8799 - val_loss : 0.0201 - val_acc: 0.4023\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c436101a7824440a887a256d1926c30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1333 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 8 - loss : 0.0286 - acc: 0.8873 - val_loss : 0.0190 - val_acc: 0.4123\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5720c21b85da4019b617c1dda830c54d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1333 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 9 - loss : 0.0272 - acc: 0.8935 - val_loss : 0.0198 - val_acc: 0.4070\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fa1ee9fb064428085bc6e367ec9f175",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1333 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 10 - loss : 0.0259 - acc: 0.8958 - val_loss : 0.0196 - val_acc: 0.4069\n",
      "\n",
      "Best acc:0.4124681055545807\n",
      "val_loss : 0.0171 - val_acc: 0.4125\n",
      "\n"
     ]
    }
   ],
   "source": [
    "set_parameter_requires_grad(model, requires_grad=True)\n",
    "train(model,10,0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a358d130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss : 0.0367 - test_acc: 0.8520\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_accuracy,test_loss=test(model, test_loader)\n",
    "print(f\"test_loss : {test_loss:.4f} - test_acc: {test_accuracy:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ad1b8c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"swin_s3_tiny_224-caltech256-e10-lr0001-t85.pt\"\n",
    "torch.save(model, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8aa44b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
